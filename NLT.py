import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from scipy.signal import find_peaks
from skimage import color as col
import Plot
import time
import PreProcess as pre


class ClusterMethod:
    def __init__(self, path, video=None):
        self.img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)
        # self.img = pre.im(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)).enhance_img
        self.img_vector = self.img.reshape(-1, 3)
        self.n_refs = 5
        self.max_cluster = 10
        self.D = self.max_cluster
        self.ssd = []
        self.video = video

    def rgb_to_lab(self):
        """
        Converts a list of RGB colors to the LAB color space using OpenCV.

        Parameters:
            rgb_colors (list of tuples): The list of RGB colors to convert.

        Returns:
            list of tuples: The corresponding list of LAB colors.
        """
        # Convert the colors to the LAB color space
        rgb_colors = self.img
        lab_colors = []
        for row in rgb_colors:
            lab_row = []
            for color in row:
                # Convert the color to a 1x1 pixel image in the RGB color space
                img = np.array([[color]])
                # Convert the pixel to the LAB color space
                lab_color = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)[0][0]
                # Append the LAB color to the row
                lab_row.append(lab_color)
            # Append the row to the list
            lab_colors.append(lab_row)
        lab_colors = np.array(lab_colors[0])
        return lab_colors

    def ElbowMethod(self):
        # Convert image to 1D array
        max_k = self.max_cluster
        img_array = np.float32(self.img.reshape((-1, 3)))

        # Initialize variables
        dists = []
        k_vals = range(1, max_k + 1)

        # Calculate distortion for each value of k
        for k in k_vals:
            kmeans = KMeans(n_clusters=k, n_init="auto")
            kmeans.fit(img_array)
            dists.append(kmeans.inertia_)

        # Calculate elbow point
        diffs = np.diff(dists)
        elbow_point = diffs.argmax() + 1

        # Return best k value
        return elbow_point

    def NoC(self):
        if self.video is not None:
            img = self.video
        else:
            img = self.img
        img = pre.im(img).enhance_img
        lab_roi = col.rgb2lab(img)
        # Calculate the histogram of each channel
        hist_l, _ = np.histogram(lab_roi[:, 0], bins=256, range=(0, 256))
        hist_a, _ = np.histogram(lab_roi[:, 1], bins=256, range=(0, 256))
        hist_b, _ = np.histogram(lab_roi[:, 2], bins=256, range=(0, 256))
        dis = self.D
        peaks_l, _ = find_peaks(hist_l, distance=dis)
        peaks_a, _ = find_peaks(hist_a, distance=dis)
        peaks_b, _ = find_peaks(hist_b, distance=dis)
        while np.std(hist_l) < len(peaks_l):
            dis += self.D
            peaks_l, _ = find_peaks(hist_l, distance=dis)
            # peaks_a, _ = find_peaks(hist_a, distance=dis)
            # peaks_b, _ = find_peaks(hist_b, distance=dis)

        num_clusters = int(np.floor((np.log(np.std(hist_l) / len(peaks_l))))) * (
            max(len(peaks_a), len(peaks_b)))+min(len(peaks_a), len(peaks_b))
        return num_clusters

    def GapStatistic(self):
        X = self.img_vector
        # Compute the reference distribution of within-cluster sum of squares (wcss)
        # using a set of reference datasets generated by bootstrapping the data
        nrefs = 5
        max_clusters = self.max_cluster
        refs = np.zeros((X.shape[1], max_clusters - 1, nrefs))
        for k in range(1, max_clusters):
            for i in range(nrefs):
                Xb = np.random.random_sample(size=X.shape)
                km = KMeans(k, n_init="auto")
                km.fit(Xb)
                refs[:, k - 1, i] = km.inertia_

        # Compute the wcss of the input data for different numbers of clusters
        ks = range(1, max_clusters)
        wcss = np.zeros(len(ks))
        for i, k in enumerate(ks):
            km = KMeans(k, n_init="auto")
            km.fit(X)
            wcss[i] = km.inertia_

        # Compute the gap statistic and the standard deviation of the reference distribution
        gaps = np.log(refs.mean(axis=2)) - np.log(wcss)
        stds = np.sqrt(1 + 1 / nrefs) * refs.std(axis=2)

        # Find the first k such that gap(k) - gap(k+1) + std(k+1) <= 0
        for i, (gap, std) in enumerate(zip(gaps, stds)):
            if i == len(gaps) - 1:
                break
            if gap[i] - gap[i + 1] + std[i + 1] <= 0:
                return i + 1

        # If no k satisfies the criterion, return the maximum k
        return max_clusters

    def cluster_image(self, k, title=None):
        if self.video is not None:
            img = self.video
        else:
            img = self.img
        # Reshape the image into a 2D array of pixels
        pixels = img.reshape(-1, 3)

        # Perform k-means clustering on the pixels
        kmeans = KMeans(n_clusters=k, random_state=0, n_init="auto").fit(pixels)
        labels = kmeans.labels_
        # Assign each pixel to its nearest centroid
        labels = kmeans.predict(pixels)

        # Reshape the labels back into the original image shape
        clustered = labels.reshape(img.shape[:2])
        blank = img.copy()
        for i in range(max(labels)+1):
            r = int(np.mean(img[np.where(clustered == i)][:,0]))
            g = int(np.mean(img[np.where(clustered == i)][:,1]))
            b = int(np.mean(img[np.where(clustered == i)][:,2]))
            col = [r, g, b]
            blank[np.where(clustered == i)] = col
        # Plot the clustered image
        # k = max(labels) + 1
        # plt.imshow(blank)
        # plt.axis('off')
        # plt.title('k = ' + str(k)+" calculated by "+title)
        # plt.show()
        return blank

    def label_img_coloring(self, k, title):
        if self.video is not None:
            img = self.video
        else:
            img = self.img
        # Reshape the image into a 2D array of pixels
        pixels = img.reshape(-1, 3)

        # Perform k-means clustering on the pixels
        kmeans = KMeans(n_clusters=k, random_state=0, n_init="auto").fit(pixels)
        labels = kmeans.labels_
        # Assign each pixel to its nearest centroid
        labels = kmeans.predict(pixels)

        labels = labels.copy()
        label_image = labels.reshape(img.shape[:2])
        # Create a colormap with 9 distinct colors
        hue_values = (label_image / 8 * 180).astype(np.uint8)
        hsv_image = np.zeros((*label_image.shape, 3), dtype=np.uint8)
        hsv_image[:, :, 0] = hue_values
        hsv_image[:, :, 1] = 255
        hsv_image[:, :, 2] = 255
        color_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)
        color_image = cv2.medianBlur(color_image, 5)
        plt.imshow(color_image)
        plt.axis('off')
        # plt.title('k = ' + str(k) + " calculated by " + title)
        plt.show()
        return color_image

class GapStatistic:
    def __init__(self, path, n_refs=10, random_state=0):
        self.n_refs = n_refs
        self.random_state = random_state

    def fit(self, X, ks=range(1, 10)):
        # Calculate the within-cluster dispersion for each K
        wcss = []
        for k in ks:
            kmeans = KMeans(n_clusters=k, random_state=self.random_state, n_init="auto")
            kmeans.fit(X)
            wcss.append(kmeans.inertia_)

        # Generate reference datasets and calculate their dispersion
        disp_refs = np.zeros(self.n_refs)
        for i in range(self.n_refs):
            random_data = np.random.rand(*X.shape)
            random_data = random_data * (X.max() - X.min()) + X.min()
            kmeans = KMeans(n_clusters=len(ks), random_state=self.random_state, n_init="auto")
            kmeans.fit(random_data)
            disp_refs[i] = kmeans.inertia_

        # Calculate the gap statistic for each K
        gap = np.log(disp_refs.mean()) - np.log(wcss)

        # Find the optimal number of clusters
        self.best_k = np.argmax(gap) + 1

        return self.best_k

def video():
    vid = cv2.VideoCapture(0)
    vid.set(cv2.CAP_PROP_FRAME_WIDTH, 100)
    vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 200)
    # Loop until the end of the video
    while True:
        ret, frame = vid.read()
        # Display the resulting frame
        cv2.imshow('frame', frame)
        method = ClusterMethod("config/phase.jpg", video=frame)
        k = method.NoC()
        # k = method.ElbowMethod()
        segment = method.cluster_image(k, "CCSE:")
        print("estimated K: ", k, "color difference:", 100-(Plot.crese(frame, segment)))
        cv2.imshow('segment', segment)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # After the loop release the cap object
    vid.release()
    # Destroy all the windows
    cv2.destroyAllWindows()